result_processor 0 8
result_processor 1 8
result_processor 2 8
result_processor 3 8
result_processor 4 8
result_processor 5 8
result_processor 6 8
result_processor 7 8
Processing experiment results. Start: 0 Step: 8
Processing experiment results. Start: 3 Step: 8
Processing experiment results. Start: 1 Step: 8
Processing experiment results. Start: 4 Step: 8
Processing experiment results. Start: 2 Step: 8
Processing experiment results. Start: 5 Step: 8
Processing experiment results. Start: 6 Step: 8
Processing experiment results. Start: 7 Step: 8
0000: analyzing
Analyzing: /root/current-deployment-data/experiment-output/0000
  > Loading trace into database...
python3 scripts/analyze/load-logs.py /root/current-deployment-data/experiment-output/0000/eventDB.sqlite /root/current-deployment-data/experiment-output/0000/slave-*/*.trc
    Events loaded: 257006
  > Loaded trace into database in 1 s.
  > Running queries on trace database: queries/ethereum.sql
SELECT *
FROM ethereum
Query time: 0.000 seconds
Rows returned: 0

Total running time: 0.000 seconds
  > Processed 'queries/ethereum.sql' in 0 s.
  > Running queries on trace database: queries/aggregates.sql
-- Truncate request table to include only rows with timestamps between:
--   the first response obtained by the last client to obtain a response
--   and
--   the last response obtained by the client first to finish obtaining responses
-- Then, cut off 5 seconds from each end.
-- We could use a view here too, but a physical table is much faster to access.
-- The script processing this file normally makes sure that
-- changes made by this script to the database are rolled back and are not persisted.
CREATE TABLE request_truncated as
SELECT *
FROM request
WHERE
  ts >= (SELECT t
    FROM (SELECT min(ts) as t
      FROM request
      WHERE event = 'REQ_FINISHED'
      GROUP BY nodeId) as tb1
    ORDER BY t
    LIMIT 1
    OFFSET (SELECT COUNT(*)
            FROM (SELECT min(ts) as t
      FROM request
      WHERE event = 'REQ_FINISHED'
      GROUP BY nodeId)) / 2)
  AND ts <= (SELECT t
    FROM (SELECT max(ts) as t
      FROM request
      WHERE event = 'REQ_SEND'
      GROUP BY nodeId) as tb1
    ORDER BY t
    LIMIT 1
    OFFSET (SELECT COUNT(*)
            FROM (SELECT min(ts) as t
      FROM request
      WHERE event = 'REQ_SEND'
      GROUP BY nodeId)) / 2);
Traceback (most recent call last):
  File "/root/scripts/analyze/run-queries.py", line 67, in <module>
    rows = cur.execute(q).fetchall()
sqlite3.OperationalError: table request_truncated already exists
  > Processed 'queries/aggregates.sql' in 2 s.
  > Running queries on trace database: queries/histograms.sql
Traceback (most recent call last):
  File "/root/scripts/analyze/run-queries.py", line 67, in <module>
    rows = cur.execute(q).fetchall()
sqlite3.OperationalError: table request_truncated already exists
-- Truncate request table to include only rows with timestamps between:
--   the first response obtained by the last client to obtain a response
--   and
--   the last request obtained by the client first to finish sending requests
-- Then, cut off 5 second from each end.
-- We could use a view here too, but a physical table is much faster to access.
-- The script processing this file normally makes sure that
-- changes made by this script to the database are rolled back and are not persisted.
CREATE TABLE request_truncated as
SELECT *
FROM request
WHERE
  ts - 2000000 >= (SELECT max(t)
    FROM (SELECT min(ts) as t
      FROM request
      WHERE event = 'REQ_FINISHED'
      GROUP BY nodeId))
  AND ts + 2000000 <= (SELECT min(t)
    FROM (SELECT max(ts) as t
      FROM request
      WHERE event = 'REQ_SEND'
      GROUP BY nodeId))
Traceback (most recent call last):
  File "/root/scripts/analyze/run-queries.py", line 67, in <module>
    rows = cur.execute(q).fetchall()
sqlite3.OperationalError: table request_truncated already exists
  > Processed 'queries/histograms.sql' in 0 s.
0001: analyzing
Analyzing: /root/current-deployment-data/experiment-output/0001
  > Loading trace into database...
python3 scripts/analyze/load-logs.py /root/current-deployment-data/experiment-output/0001/eventDB.sqlite /root/current-deployment-data/experiment-output/0001/slave-*/*.trc
    Events loaded: 509394
  > Loaded trace into database in 2 s.
  > Running queries on trace database: queries/ethereum.sql
SELECT *
FROM ethereum
Query time: 0.000 seconds
Rows returned: 0

Total running time: 0.000 seconds
  > Processed 'queries/ethereum.sql' in 0 s.
  > Running queries on trace database: queries/aggregates.sql
-- Truncate request table to include only rows with timestamps between:
--   the first response obtained by the last client to obtain a response
--   and
--   the last response obtained by the client first to finish obtaining responses
-- Then, cut off 5 seconds from each end.
-- We could use a view here too, but a physical table is much faster to access.
-- The script processing this file normally makes sure that
-- changes made by this script to the database are rolled back and are not persisted.
CREATE TABLE request_truncated as
SELECT *
FROM request
WHERE
  ts >= (SELECT t
    FROM (SELECT min(ts) as t
      FROM request
      WHERE event = 'REQ_FINISHED'
      GROUP BY nodeId) as tb1
    ORDER BY t
    LIMIT 1
    OFFSET (SELECT COUNT(*)
            FROM (SELECT min(ts) as t
      FROM request
      WHERE event = 'REQ_FINISHED'
      GROUP BY nodeId)) / 2)
  AND ts <= (SELECT t
    FROM (SELECT max(ts) as t
      FROM request
      WHERE event = 'REQ_SEND'
      GROUP BY nodeId) as tb1
    ORDER BY t
    LIMIT 1
    OFFSET (SELECT COUNT(*)
            FROM (SELECT min(ts) as t
      FROM request
      WHERE event = 'REQ_SEND'
      GROUP BY nodeId)) / 2);
Traceback (most recent call last):
  File "/root/scripts/analyze/run-queries.py", line 67, in <module>
    rows = cur.execute(q).fetchall()
sqlite3.OperationalError: table request_truncated already exists
  > Processed 'queries/aggregates.sql' in 4 s.
  > Running queries on trace database: queries/histograms.sql
Traceback (most recent call last):
  File "/root/scripts/analyze/run-queries.py", line 67, in <module>
    rows = cur.execute(q).fetchall()
sqlite3.OperationalError: table request_truncated already exists
-- Truncate request table to include only rows with timestamps between:
--   the first response obtained by the last client to obtain a response
--   and
--   the last request obtained by the client first to finish sending requests
-- Then, cut off 5 second from each end.
-- We could use a view here too, but a physical table is much faster to access.
-- The script processing this file normally makes sure that
-- changes made by this script to the database are rolled back and are not persisted.
CREATE TABLE request_truncated as
SELECT *
FROM request
WHERE
  ts - 2000000 >= (SELECT max(t)
    FROM (SELECT min(ts) as t
      FROM request
      WHERE event = 'REQ_FINISHED'
      GROUP BY nodeId))
  AND ts + 2000000 <= (SELECT min(t)
    FROM (SELECT max(ts) as t
      FROM request
      WHERE event = 'REQ_SEND'
      GROUP BY nodeId))
Traceback (most recent call last):
  File "/root/scripts/analyze/run-queries.py", line 67, in <module>
    rows = cur.execute(q).fetchall()
sqlite3.OperationalError: table request_truncated already exists
  > Processed 'queries/histograms.sql' in 0 s.
0002: analyzing
Analyzing: /root/current-deployment-data/experiment-output/0002
  > Loading trace into database...
python3 scripts/analyze/load-logs.py /root/current-deployment-data/experiment-output/0002/eventDB.sqlite /root/current-deployment-data/experiment-output/0002/slave-*/*.trc
Finished processing results. First unprocessed: 9
Finished processing results. First unprocessed: 8
    Events loaded: 775388
  > Loaded trace into database in 3 s.
  > Running queries on trace database: queries/ethereum.sql
SELECT *
FROM ethereum
Query time: 0.000 seconds
Rows returned: 0

Total running time: 0.000 seconds
  > Processed 'queries/ethereum.sql' in 0 s.
  > Running queries on trace database: queries/aggregates.sql
Finished processing results. First unprocessed: 7
Finished processing results. First unprocessed: 4
Finished processing results. First unprocessed: 5
Finished processing results. First unprocessed: 3
Finished processing results. First unprocessed: 6
-- Truncate request table to include only rows with timestamps between:
--   the first response obtained by the last client to obtain a response
--   and
--   the last response obtained by the client first to finish obtaining responses
-- Then, cut off 5 seconds from each end.
-- We could use a view here too, but a physical table is much faster to access.
-- The script processing this file normally makes sure that
-- changes made by this script to the database are rolled back and are not persisted.
CREATE TABLE request_truncated as
SELECT *
FROM request
WHERE
  ts >= (SELECT t
    FROM (SELECT min(ts) as t
      FROM request
      WHERE event = 'REQ_FINISHED'
      GROUP BY nodeId) as tb1
    ORDER BY t
    LIMIT 1
    OFFSET (SELECT COUNT(*)
            FROM (SELECT min(ts) as t
      FROM request
      WHERE event = 'REQ_FINISHED'
      GROUP BY nodeId)) / 2)
  AND ts <= (SELECT t
    FROM (SELECT max(ts) as t
      FROM request
      WHERE event = 'REQ_SEND'
      GROUP BY nodeId) as tb1
    ORDER BY t
    LIMIT 1
    OFFSET (SELECT COUNT(*)
            FROM (SELECT min(ts) as t
      FROM request
      WHERE event = 'REQ_SEND'
      GROUP BY nodeId)) / 2);
Traceback (most recent call last):
  File "/root/scripts/analyze/run-queries.py", line 67, in <module>
    rows = cur.execute(q).fetchall()
sqlite3.OperationalError: table request_truncated already exists
  > Processed 'queries/aggregates.sql' in 6 s.
  > Running queries on trace database: queries/histograms.sql
Traceback (most recent call last):
  File "/root/scripts/analyze/run-queries.py", line 67, in <module>
    rows = cur.execute(q).fetchall()
sqlite3.OperationalError: table request_truncated already exists
-- Truncate request table to include only rows with timestamps between:
--   the first response obtained by the last client to obtain a response
--   and
--   the last request obtained by the client first to finish sending requests
-- Then, cut off 5 second from each end.
-- We could use a view here too, but a physical table is much faster to access.
-- The script processing this file normally makes sure that
-- changes made by this script to the database are rolled back and are not persisted.
CREATE TABLE request_truncated as
SELECT *
FROM request
WHERE
  ts - 2000000 >= (SELECT max(t)
    FROM (SELECT min(ts) as t
      FROM request
      WHERE event = 'REQ_FINISHED'
      GROUP BY nodeId))
  AND ts + 2000000 <= (SELECT min(t)
    FROM (SELECT max(ts) as t
      FROM request
      WHERE event = 'REQ_SEND'
      GROUP BY nodeId))
Traceback (most recent call last):
  File "/root/scripts/analyze/run-queries.py", line 67, in <module>
    rows = cur.execute(q).fetchall()
sqlite3.OperationalError: table request_truncated already exists
  > Processed 'queries/histograms.sql' in 0 s.
Finished processing results. First unprocessed: 10
Finished continuous result analysis.
